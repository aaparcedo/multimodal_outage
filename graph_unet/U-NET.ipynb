{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 128, 128])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('grayscale_image.jpeg')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)\n",
    "image = image.expand(3, 3, 128, 128)\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2))\n",
    "                \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contraction(nn.Module):\n",
    "    def __init__(self, in_channels): \n",
    "        super().__init__()\n",
    "        self.inc = (DoubleConv(in_channels, 4))\n",
    "        self.down1 = (Down(4, 8))\n",
    "        self.down2 = (Down(8, 16))\n",
    "        self.down3 = (Down(16, 32))\n",
    "        self.down4 = (Down(32, 64))\n",
    "        \n",
    "        self.feature_maps = []\n",
    "        \n",
    "    def feature_maps(self): \n",
    "\n",
    "        return self.feature_maps\n",
    "    \n",
    "    def flattened_size(self): \n",
    "        \n",
    "        return self.flattened_size\n",
    "    \n",
    "    def original_shape(self): \n",
    "        \n",
    "        return self.original_shape\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        x1 = self.inc(input)\n",
    "        self.feature_maps.append(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        self.feature_maps.append(x2)\n",
    "\n",
    "        x3 = self.down2(x2)\n",
    "        self.feature_maps.append(x3)\n",
    "\n",
    "        x4 = self.down3(x3)\n",
    "        self.feature_maps.append(x4)\n",
    "\n",
    "        x5 = self.down4(x4)\n",
    "        batch, _, _, _ = x5.shape\n",
    "        encoder_input = x5.view(batch, -1)\n",
    "    \n",
    "        return encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_dimension):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.downsized_image_dimension = image_dimension / 16\n",
    "        self.first_layer_size = int(self.downsized_image_dimension * self.downsized_image_dimension * 64)\n",
    "        self.fc1 = nn.Linear(self.first_layer_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 16)\n",
    "        self.fc7 = nn.Linear(16, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, batch_size, image_dimension):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.downsized_image_dimension = int(image_dimension / 16)\n",
    "        self.output_layer_size = int(self.downsized_image_dimension * self.downsized_image_dimension * 64)\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 512)\n",
    "        self.fc5 = nn.Linear(512, self.output_layer_size) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        x = x.view(self.batch_size, 64, self.downsized_image_dimension, self.downsized_image_dimension)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expansion(nn.Module):\n",
    "    def __init__(self, output_channels): \n",
    "        super(Expansion, self).__init__()\n",
    "        self.up1 = (Up(64, 32))\n",
    "        self.up2 = (Up(32, 16))\n",
    "        self.up3 = (Up(16, 8))\n",
    "        self.up4 = (Up(8, 4))\n",
    "        self.outc = (OutConv(4, output_channels))\n",
    "        \n",
    "    def forward(self, input, feature_maps): \n",
    "        x = self.up1(input, feature_maps[-1])\n",
    "        x = self.up2(x, feature_maps[-2])\n",
    "        x = self.up3(x, feature_maps[-3])\n",
    "        x = self.up4(x, feature_maps[-4])\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modified_UNET(nn.Module): \n",
    "    def __init__(self, batch_size=67, input_channels=3, output_channels=3, feature_vector_size=8, image_dimension=128):\n",
    "        super(Modified_UNET, self).__init__()\n",
    "        self.contraction = Contraction(input_channels)\n",
    "        self.encoder = Encoder(image_dimension)\n",
    "        self.decoder = Decoder(feature_vector_size, batch_size, image_dimension)\n",
    "        self.expansion = Expansion(output_channels)\n",
    "        \n",
    "    def forward(self, input): \n",
    "        output = self.contraction(input)\n",
    "        print(output.shape)\n",
    "        \n",
    "        output = self.encoder(output)\n",
    "        print(output.shape)\n",
    "        \n",
    "        output = self.decoder(output)\n",
    "        print(output.shape)\n",
    "        \n",
    "        feature_maps = self.contraction.feature_maps\n",
    "        predicted_results = self.expansion(output, feature_maps)\n",
    "        return predicted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4096])\n",
      "torch.Size([3, 8])\n",
      "torch.Size([3, 64, 8, 8])\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "model = Modified_UNET(3)\n",
    "output = model(image)\n",
    "print(output.shape) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
